{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda1b4d65181bfe435290e55078ed6e0090",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets import TextDataset\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "from datasets import load_dataset, list_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_pooling_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "The bare Bert Model transformer outputting raw hidden-states without any specific head on top.\n",
      "\n",
      "This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic\n",
      "methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,\n",
      "pruning heads etc.)\n",
      "\n",
      "This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__ subclass.\n",
      "Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general\n",
      "usage and behavior.\n",
      "\n",
      "Parameters:\n",
      "    config (:class:`~transformers.BertConfig`): Model configuration class with all the parameters of the model.\n",
      "        Initializing with a config file does not load the weights associated with the model, only the configuration.\n",
      "        Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.\n",
      "\n",
      "\n",
      "The model can behave as an encoder (with only self-attention) as well\n",
      "as a decoder, in which case a layer of cross-attention is added between\n",
      "the self-attention layers, following the architecture described in `Attention is all you need\n",
      "<https://arxiv.org/abs/1706.03762>`__ by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\n",
      "Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin.\n",
      "\n",
      "To behave as an decoder the model needs to be initialized with the\n",
      ":obj:`is_decoder` argument of the configuration set to :obj:`True`.\n",
      "To be used in a Seq2Seq model, the model needs to initialized with both :obj:`is_decoder`\n",
      "argument and :obj:`add_cross_attention` set to :obj:`True`; an\n",
      ":obj:`encoder_hidden_states` is then expected as an input to the forward pass.\n",
      "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/lib/python3.7/site-packages/transformers/modeling_bert.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "BertModel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/home/macab/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        module\n",
      "\u001b[0;31mString form:\u001b[0m <module 'Datasets.TextDataset' from '/home/macab/research/torchmm/torchmm/Datasets/TextDataset.py'>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/research/torchmm/torchmm/Datasets/TextDataset.py\n",
      "\u001b[0;31mDocstring:\u001b[0m   <no docstring>\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "datasets = TextDataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library\n",
      "when created with the :meth:`AutoTokenizer.from_pretrained` class method.\n",
      "\n",
      "This class cannot be instantiated directly using ``__init__()`` (throws an error).\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/lib/python3.7/site-packages/transformers/tokenization_auto.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "AutoTokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Demo:\n",
    "    '''demo class'''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      demo class\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "Demo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Splits the tensor into chunks. Each chunk is a view of the original tensor.\n",
      "\n",
      "If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will\n",
      "be split into equally sized chunks (if possible). Last chunk will be smaller if\n",
      "the tensor size along the given dimension :attr:`dim` is not divisible by\n",
      ":attr:`split_size`.\n",
      "\n",
      "If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split\n",
      "into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according\n",
      "to :attr:`split_size_or_sections`.\n",
      "\n",
      "Arguments:\n",
      "    tensor (Tensor): tensor to split.\n",
      "    split_size_or_sections (int) or (list(int)): size of a single chunk or\n",
      "        list of sizes for each chunk\n",
      "    dim (int): dimension along which to split the tensor.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/lib/python3.7/site-packages/torch/functional.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "torch.split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}